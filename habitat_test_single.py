import time
import habitat_sim
from habitat_sim.utils import common as utils
import numpy as np
import rerun as rr
import rerun.blueprint as rrb
from habitat_sim import ActionSpec, ActuationSpec
from scipy.spatial.transform import Rotation as R
from mapping import Navigator
from vision_models.grad_eclip_model import GradEclipModel
#from vision_models.clip_dense import ClipModel
#from vision_models.grad_eclip_softmax_model import GradEclipSoftmaxModel
from vision_models.yolo_world_detector import YOLOWorldDetector
from planning import Planning, Controllers
from config import *
from mapping import rerun_logger

from eval.dataset_utils.object_nav_utils import object_nav_gen


if __name__ == "__main__":
    config = load_config().Conf
    if type(config.controller) == HabitatControllerConf:
        pass
    else:
        raise NotImplementedError("Spot controller not suited for habitat sim")

    # GradEclipModel ì‚¬ìš© (feature_dim=1) - ë‹¨ìˆœí™”ëœ ë²„ì „
    model = GradEclipModel(model_name="ViT-L/14", device="cuda", heatmap_scale_factor=1.0)
    print(f"ğŸ”§ GradEclipModel ì´ˆê¸°í™” ì™„ë£Œ - ë‹¨ìˆœí™”ëœ ë²„ì „ (gamma ë³´ì • ì œê±°)")
    detector = YOLOWorldDetector(0.6)
    mapper = Navigator(model, detector, config)
    logger = rerun_logger.RerunLogger(mapper, False, "", debug=False) if config.log_rerun else None
    
    # ë‹¨ì¼ ëª©í‘œ ê°ì²´
    query_texts_for_clip = ["toilet"]  # ìœ ì‚¬ë„ ì§€ë„ì— ì‚¬ìš©í•  í…ìŠ¤íŠ¸ë“¤
    detect_class = "toilet" 
    mapper.set_query([detect_class])
    # Grad-ECLIPì˜ ê²½ìš° ë³„ë„ì˜ í…ìŠ¤íŠ¸ ì„ë² ë”© ì„¤ì •ì´ í•„ìš” ì—†ìŒ
    # get_image_features()ì—ì„œ ì§ì ‘ ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì„œ heatmap ìƒì„±
    mapper.query_text = query_texts_for_clip
    mapper.previous_sims = None
    query = ", ".join(query_texts_for_clip)
    hm3d_path = "datasets/scene_datasets/hm3d"

    backend_cfg = habitat_sim.SimulatorConfiguration()   
    backend_cfg.scene_id = hm3d_path + "/val/00853-5cdEh9F2hJL/5cdEh9F2hJL.basis.glb"
    #"/val/00878-XB4GS9ShBRE/XB4GS9ShBRE.basis.glb"
    #"/val/00877-4ok3usBNeis/4ok3usBNeis.basis.glb"
    #"/val/00824-Dd4bFSTQ8gi/Dd4bFSTQ8gi.basis.glb"
    #"/val/00829-QaLdnwvtxbs/QaLdnwvtxbs.basis.glb"
    #"/val/00835-q3zU7Yy5E5s/q3zU7Yy5E5s.basis.glb"
    #"/val/00832-qyAac8rV8Zk/qyAac8rV8Zk.basis.glb"
    #"/val/00880-Nfvxx8J5NCo/Nfvxx8J5NCo.basis.glb"
    #"/val/00853-5cdEh9F2hJL/5cdEh9F2hJL.basis.glb" -> TV
    backend_cfg.scene_dataset_config_file = hm3d_path + "/hm3d_annotated_basis.scene_dataset_config.json"

    hfov = 90
    rgb = habitat_sim.CameraSensorSpec()
    rgb.uuid = "rgb"

    rgb.hfov = hfov
    rgb.position = np.array([0, 0.88, 0])
    rgb.sensor_type = habitat_sim.SensorType.COLOR
    res_x = 640
    res_y = 640
    rgb.resolution = [res_y, res_x]

    depth = habitat_sim.CameraSensorSpec()
    depth.uuid = "depth"
    depth.hfov = hfov
    depth.position = np.array([0, 0.88, 0])
    depth.sensor_type = habitat_sim.SensorType.DEPTH
    depth.resolution = [res_y, res_x]

    hfov = np.deg2rad(hfov)
    focal_length = (res_x / 2) / np.tan(hfov / 2)
    principal_point_x = res_x / 2
    principal_point_y = res_y / 2
    K = np.array([
        [focal_length, 0, principal_point_x],
        [0, focal_length, principal_point_y],
        [0, 0, 1]
    ])

    agent_cfg = habitat_sim.agent.AgentConfiguration(action_space=dict(
        move_forward=ActionSpec("move_forward", ActuationSpec(amount=0.25)),
        turn_left=ActionSpec("turn_left", ActuationSpec(amount=5.0)),
        turn_right=ActionSpec("turn_right", ActuationSpec(amount=5.0)),
    ))
    agent_cfg.sensor_specifications = [rgb, depth]

    sim_cfg = habitat_sim.Configuration(backend_cfg, [agent_cfg])
    sim = habitat_sim.Simulator(sim_cfg)

################ ìµœë‹¨ ê±°ë¦¬ êµ¬í•˜ê¸° ################
    # ì‹œì‘ ìœ„ì¹˜
    start_state = sim.get_agent(0).get_state()
    start_pos = np.array(start_state.position, dtype=np.float32)

    objs = [o for o in sim.semantic_scene.objects if detect_class in o.category.name().lower()]

    # ê°ì²´ ì¤‘ì‹¬ ì£¼ë³€ ë§ ìƒ˜í”Œë§ìœ¼ë¡œ ì—”ë“œí¬ì¸íŠ¸ í›„ë³´ë¥¼ ìƒì„± (ë„¤ë¹„ê²Œì´ì…˜ ê°€ëŠ¥í•œ ì§€ì ë§Œ ì±„íƒ)
    endpoints = []
    for obj in objs:
        center = np.array(obj.aabb.center, dtype=np.float32)
        for radius in [0.6, 0.8, 1.0, 1.2]:
            for angle in np.linspace(0, 2 * np.pi, 16, endpoint=False):
                candidate = center + np.array([radius * np.cos(angle), 0.0, radius * np.sin(angle)], dtype=np.float32)
                # ë‚´ë¹„ê²Œì´ë¸” í¬ì¸íŠ¸ë¡œ ìŠ¤ëƒ… ë° í•„í„°ë§
                snapped = sim.pathfinder.snap_point(candidate)
                if (not np.isnan(snapped).any()) and sim.pathfinder.is_navigable(snapped) and sim.pathfinder.island_radius(snapped) >= 1.0:
                    endpoints.append(np.array(snapped, dtype=np.float32))

    # L* ê³„ì‚°
    if not endpoints:
        print(f"{detect_class} í›„ë³´ ëª©í‘œì ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. L* ê³„ì‚° ë¶ˆê°€")
        L_star = None
    else:
        L_star, _ = object_nav_gen.geodesic_distance(sim, start_pos, endpoints) # ìµœë‹¨ê±°ë¦¬ ë½‘ê¸°! ì§€ì˜¤ë°ì‹ ë°©ë²•ìœ¼ë¡œ
        print(f"ìµœë‹¨ê±°ë¦¬ L*: {L_star:.3f} m")

################ ìµœë‹¨ ê±°ë¦¬ êµ¬í•˜ê¸° ë ################

    # ê²½ë¡œ ê¸¸ì´ ëˆ„ì  ë³€ìˆ˜
    prev_pos = start_pos.copy()
    path_length = 0.0

    # ì´ˆê¸° 360ë„ íšŒì „ ì‹œí€€ìŠ¤
    initial_sequence = ["turn_left"] * 28 * 2
    running = True
    autonomous = True
    controller = Controllers.HabitatController(sim, config.controller)

    while running:
        action = None
        if len(initial_sequence):
            action = initial_sequence[0]
            initial_sequence.pop(0)
            if not len(initial_sequence):
                mapper.one_map.reset_checked_map()
        elif autonomous:
            action = None
            state = sim.get_agent(0).get_state()
            orientation = state.rotation
            q0 = orientation.x
            q1 = orientation.y
            q2 = orientation.z
            q3 = orientation.w
            r = R.from_quat([q0, q1, q2, q3])
            pitch, yaw, roll = r.as_euler("yxz")
            yaw = pitch
            current_pos = np.array([[-state.position[2]], [-state.position[0]], [state.position[1]]])
            path = mapper.get_path()
            if path and len(path) > 1:
                path = Planning.simplify_path(np.array(path))
                path = path.astype(np.float32)
                for i in range(path.shape[0]):
                    path[i, :] = mapper.one_map.px_to_metric(path[i, 0], path[i, 1])
                print(f"[DEBUG] ê²½ë¡œ ì¶”ì¢… ì¤‘... ê²½ë¡œ ê¸¸ì´: {len(path)}, ëª©í‘œ: {path[-1]}")
                controller.control(current_pos, yaw, path)
                # HabitatControllerëŠ” ì§ì ‘ ì‹œë®¬ë ˆì´í„°ë¥¼ ì œì–´í•˜ë¯€ë¡œ ë³„ë„ ì•¡ì…˜ ë¶ˆí•„ìš”
                observations = sim.get_sensor_observations()
                action = None  # sim.step() ê±´ë„ˆë›°ê¸°
            else:
                print(f"[DEBUG] ê²½ë¡œ ì—†ìŒ ë˜ëŠ” ê²½ë¡œê°€ ë„ˆë¬´ ì§§ìŒ: {path}")
                # ê²½ë¡œê°€ ì—†ìœ¼ë©´ ì œìë¦¬ì—ì„œ íšŒì „í•˜ë©° íƒìƒ‰
                action = "turn_left"
        if action and action != "enter_query":
            observations = sim.step(action)
        elif action is None and autonomous:
            # ì»¨íŠ¸ë¡¤ëŸ¬ê°€ ì§ì ‘ ì œì–´í•œ ê²½ìš°, ì´ë¯¸ observationsë¥¼ ë°›ì•˜ìœ¼ë¯€ë¡œ ê³„ì† ì§„í–‰
            pass
        elif not autonomous:
            continue

        state = sim.get_agent(0).get_state()
        # ì‹¤ì œ ì´ë™ê±°ë¦¬ ëˆ„ì  (ì›”ë“œ ì¢Œí‘œê³„)
        cur_world_pos = np.array(state.position, dtype=np.float32)
        path_length += np.linalg.norm(cur_world_pos - prev_pos)
        prev_pos = cur_world_pos
        pos = np.array(([[-state.position[2]], [-state.position[0]], [state.position[1]]]))
        mapper.set_camera_matrix(K)
        orientation = state.rotation
        q0 = orientation.x
        q1 = orientation.y
        q2 = orientation.z
        q3 = orientation.w
        r = R.from_quat([q0, q1, q2, q3])
        pitch, yaw, roll = r.as_euler("yxz")
        r = R.from_euler("xyz", [0, 0, pitch])
        r = r.as_matrix()
        transformation_matrix = np.hstack((r, pos))
        transformation_matrix = np.vstack((transformation_matrix, np.array([0, 0, 0, 1])))
        t = time.time()
        obj_found = mapper.add_data(
            observations["rgb"][:, :, :-1].transpose(2, 0, 1), observations["depth"].astype(np.float32),
            transformation_matrix)
        print("Time taken to add data: ", time.time() - t)
        
        # íˆíŠ¸ë§µ ìŠ¤ì¼€ì¼ ë””ë²„ê¹…
        if hasattr(mapper.one_map, 'feature_map') and mapper.one_map.feature_map is not None:
            feature_map = mapper.one_map.feature_map
            if feature_map.shape[0] > 0:  # feature_dim > 0
                max_val = feature_map.max().item()
                min_val = feature_map.min().item()
                mean_val = feature_map.mean().item()
                print(f"ğŸ“Š í˜„ì¬ íˆíŠ¸ë§µ - Max: {max_val:.6f}, Min: {min_val:.6f}, Mean: {mean_val:.6f}")
                print(f"   ìŠ¤ì¼€ì¼ íŒ©í„°: {model.heatmap_scale_factor}")

        cam_x = pos[0, 0]
        cam_y = pos[1, 0]
        
        if logger:
            rr.log("camera/rgb", rr.Image(observations["rgb"]))
            rr.log("camera/depth", rr.Image((observations["depth"] - observations["depth"].min()) / (
                    observations["depth"].max() - observations["depth"].min())))
            rr.log("goal/text", rr.TextLog(query))
            logger.log_map()
            logger.log_pos(cam_y, cam_x)
        if obj_found:
            if L_star is not None and L_star > 0:
                spl = min(1.0, L_star / max(path_length, L_star))
                print(f"ëª©í‘œ ê°ì²´({query})ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤! SPL: {spl:.4f} (L*={L_star:.3f}, L={path_length:.3f})")
            else:
                print(f"ëª©í‘œ ê°ì²´({query})ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤! (L* ë¯¸ê³„ì‚°ìœ¼ë¡œ SPL ì¶œë ¥ ë¶ˆê°€)")
            break